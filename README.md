# ğŸ“ Exam Stress Balancer
### Reinforcement Learning Based Adaptive Study Planning System

Exam Stress Balancer is an AI-driven adaptive study planning system that models a student's cognitive state and recommends optimal actions (Study / Revise / Break) using Reinforcement Learning (SARSA).

This project simulates real-world academic pressure and dynamically balances:

- ğŸ“š Learning gain
- ğŸ§  Memory retention
- ğŸ˜“ Stress levels
- ğŸ’¤ Fatigue accumulation
- â³ Time urgency before exams

---

## ğŸš€ Project Overview

Traditional study planning is static. This system adapts decisions based on:

- Current fatigue
- Current stress
- Memory retention
- Days left before exam
- Exam difficulty

The agent learns an optimal strategy through experience using SARSA (State-Action-Reward-State-Action) learning.

---

## ğŸ§  Reinforcement Learning Design

### ğŸ”¹ State Space (5D Discretized)
(fatigue_level, stress_level, retention_level, urgency, difficulty)

- Fatigue: LOW / MEDIUM / HIGH  
- Stress: LOW / MEDIUM / HIGH  
- Retention: LOW / MEDIUM / HIGH  
- Urgency: LOW / MEDIUM / HIGH  
- Difficulty: EASY / MEDIUM / HARD  

---

### ğŸ”¹ Actions
| Action ID | Meaning |
|-----------|---------|
| 0 | Study |
| 1 | Revise |
| 2 | Break / Sleep |

---

### ğŸ”¹ Reward Engineering Includes

- Learning gain bonus
- Burnout penalties
- Overstudying penalty
- Stress sensitivity
- Retention zone bonus
- Urgency-based reward adjustment (when days_left â‰¤ 3)

---

## ğŸ“Š Training Details

- Algorithm: **SARSA**
- Episodes: 2000+
- Epsilon-greedy exploration
- Learned Q-table size: ~160+ states
- Final Average Reward: Positive (~47+)
- Policy saved as: `trained_policy.pkl`

---

## ğŸŒ Web Application

Built using:

- **FastAPI** (Backend API)
- **Uvicorn** (ASGI Server)
- **Custom HTML + CSS UI**
- Glassmorphism UI Design
- Real-time prediction endpoint (`/predict`)

Users input:

- Fatigue
- Stress
- Retention
- Days until exam
- Exam difficulty

System outputs recommended action.

---

## ğŸ“ Project Structure


exam-stress-balancer-rl/
â”‚
â”œâ”€â”€ env/
â”‚ â”œâ”€â”€ student_environment.py
â”‚ â”œâ”€â”€ train_sarsa.py
â”‚ â”œâ”€â”€ agent/
â”‚ â”‚ â”œâ”€â”€ sarsa_agent.py
â”‚ â”‚ â””â”€â”€ state_discretizer.py
â”‚
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ index.html
â”‚
â”œâ”€â”€ static/
â”‚ â””â”€â”€ style.css
â”‚
â”œâ”€â”€ api.py
â”œâ”€â”€ trained_policy.pkl
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## âš™ï¸ Installation & Run
### 1ï¸âƒ£ Clone Repository

git clone https://github.com/YOUR\_USERNAME/exam-stress-balancer.git
cd exam-stress-balancer


### 2ï¸âƒ£ Create Virtual Environment
python -m venv venv
venv\Scripts\activate # Windows


### 3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


### 4ï¸âƒ£ Train Model (Optional)
python -m env.train_sarsa


### 5ï¸âƒ£ Run Web App
python -m uvicorn api:app --reload
open:http://127.0.0.1:8000


---

## ğŸ§ª Test Scenarios

The system was tested on 11 structured academic stress scenarios including:

- High stress & low retention
- Low stress & high retention
- High urgency exam
- Burnout conditions
- Easy vs Hard exam comparison

Model performance stabilized with positive reward trends.

---

## ğŸ¯ Academic Objective

This project demonstrates:

- Custom RL environment modeling
- Reward shaping design
- Cognitive state simulation
- Policy learning via SARSA
- Full-stack AI deployment

---

## ğŸ”® Future Roadmap

### Phase 2
- Dashboard analytics
- Stress & fatigue trend graphs
- Burnout warning system
- Decision explanation layer

### Phase 3
- LLM integration for syllabus parsing
- Chapter upload planning
- AI-generated study schedules
- Mobile app version

---

## ğŸ‘¨â€ğŸ’» Author

Developed as part of academic research in AI-driven adaptive learning systems.

---

## ğŸ“œ License

Academic & Educational Use


